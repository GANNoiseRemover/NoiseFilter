Here you can check out the USE CASE and its description for out project.

## **1. USE CASE diagrams ->**
   
![Error](https://github.com/GANNoiseRemover/NoiseFilter/blob/main/img/USE_CASE1.png)
![Error](https://github.com/GANNoiseRemover/NoiseFilter/blob/main/img/USE_CASE2.png)

---
## **2.USE CASE description ->**
---
---
# **UC1 - Preparation for Deliver Clean Audio**

## Use Case: Collect Data (Clean + Noisy Recordings)
**Use Case Name:** Collect Data (Clean + Noisy Recordings)

**Actor:** Development Team

**Description:** Collect audio recordings with noise (from hearing aid device) and clean audio recordings necessary for training and testing the noise reduction model.

**Preconditions:**
* Developers have access to audio sources.
* Tools for recording and storing audio are ready.
  
**Postconditions:**
* Training and test audio data are collected and stored in a usable format.
  
**Main Flow:**
1. Identify sources of audio recordings (various noise conditions, different speakers).
2. Record or collect existing audio data.
3. Classify audio as “clean” or “noisy.”
4. Store the data for model training and testing.

**Alternative Flows / Extensions:**
* If recordings contain excessive noise, discard or re-record them.
* If insufficient data is collected, repeat the data collection process.

---

# **US2 - Model Training & Improvement (GAN (Noise Reduction) + Autoencoder)**
**Use Case Name:** Model Training & Improvement

**Actor:** Development Team

**Description:** Develop, train, and apply the AI model (GAN + Autoencoder) for noise reduction, generating processed audio for quality evaluation.

**Preconditions:**
* Training and test data are collected (UC1).
* Developers have prepared code and model algorithms.
  
**Postconditions:**
* The trained model is capable of reducing noise on audio samples.
* Processed audio is generated for evaluation.
  
**Main Flow:**
1. Implement the code for the model (GAN + Autoencoder).
2. Load collected training data.
3. Train the model using training data.
4. Apply the trained model to test audio for noise reduction.
5. Adjust model parameters based on preliminary results to optimize performance.
   
**Alternative Flows / Extensions:**
* If the model fails to train properly, adjust hyperparameters or model architecture.
* If processed audio is unsatisfactory, revisit training with additional data or parameter tuning.

---

# **US3 - Evaluate Audio Quality (PESQ, STOI)
**Use Case Name:** Evaluate Audio Quality

**Actor:** Development Team

**Description:** Assess the quality of the processed audio generated by the trained model using PESQ and STOI metrics.

**Preconditions:**
* Model is trained and applied to test audio (UC2).
* Test audio is available.
  
**Postconditions:**
* Quality metrics (PESQ, STOI) are obtained, indicating the effectiveness of the model.
* Decision is made whether the model is ready for deployment or needs improvement.
  
**Main Flow:**
1. Load the original test audio and the test audio processed by the trained model.
2. Compute PESQ and STOI metrics for both versions of audio.
3. Analyze the results to determine model performance.
   
**Alternative Flows / Extensions:**
* If metrics are below acceptable thresholds, return to UC2 to retrain or adjust the model.

---

## **US4 - Deploy Optimized Model (to Runtime Device)
**Use Case Name:** Deploy Optimized Model

**Actor:** Development Team

**Description:** Deploy the trained, tested, and optimized model to the runtime hearing aid device for end-user operation.

**Preconditions:**
* Model is trained, applied to test audio, and evaluated (UC2 & UC3).
* Runtime device is ready for deployment.
  
**Postconditions:**
* AI model is successfully deployed on the device.
* Deliver Clean Audio functionality is ready for use by the user.
  
**Main Flow:**
1. Prepare the model for deployment (conversion, packaging).
2. Transfer the model to the runtime device.
3. Verify correct installation and functionality of the deployed model.
   
**Alternative Flows / Extensions:**
* If deployment fails, fix errors and repeat the deployment process.

---




























**UC0 – Power On/Off Device (Potentiometer Switch)**

* **Actor**: User
* **Preconditions**: Device is powered by battery.
* **Postconditions**: Device is either active (ON) or inactive (OFF).
* **Main Flow**:
  1. User rotates the potentiometer to the ON position.
  2. System initializes microphone, amplifier, and processing unit.
  3. User rotates potentiometer back to switch OFF when not in use.
* **Alternative Flow**:
  * If the battery is depleted, the device fails to power ON.

---

## **UC01 – Adjust Volume (Potentiometer Control)**
* **Actor**: User
* **Preconditions**: Device must be ON (**extends UC0**).
* **Postconditions**: Amplification level is changed.
* **Main Flow**:
  1. User adjusts potentiometer to increase or decrease volume.
  2. System updates amplifier gain accordingly.
* **Alternative Flow**:
  * If the device is OFF, volume adjustment has no effect.

---

## **UC1 – Capture Audio Input (Microphone)** -> Maybe its worth to make another use case diagram for detailed description of this USE CASE????
* **Actor**: System (automatic action once ON)
* **Preconditions**: Device is ON.
* **Postconditions**: Audio signal (speech + noise) is captured.
* **Main Flow**:
  1. Microphone receives surrounding sounds.
  2. Converts sound waves into electrical signals.

---

## **UC2 – Amplify Audio Signal (Hearing Aid Circuit)**
* **Actor**: System
* **Preconditions**: Audio input is available from UC1.
* **Postconditions**: Audio signal strength is increased.
* **Main Flow**:
  1. Amplifier boosts captured audio signal.
  2. Output is forwarded for noise reduction.

---

## **UC3 – Noise Reduction (GAN/Autoencoder Model)**
* **Actor**: System
* **Preconditions**: Amplified signal is available.
* **Postconditions**: Noise-reduced audio signal is produced.
* **Main Flow**:
  1. Amplified audio is processed through GAN/Autoencoder.
  2. Background noise is suppressed.
  3. Speech component is preserved.
* **Included Use Cases**:
  * **UC5 (Model Training & Improvement)** – updated model enhances noise reduction.
  * **UC6 (Evaluate Audio Quality)** – feedback improves processing quality.

---

## **UC4 – Deliver Clean Audio (Headphones/Speaker)**
* **Actor**: System
* **Preconditions**: Noise-reduced signal is available.
* **Postconditions**: User hears amplified, clear audio.
* **Main Flow**:
  1. System outputs processed audio to earphone.
  2. User perceives improved speech clarity.

---

## **UC5 – Model Training & Improvement (GAN + Deep Learning)**
* **Actor**: Development Team
* **Preconditions**: Training dataset (speech + noise samples) is available.
* **Postconditions**: Improved noise-reduction model is produced.
* **Main Flow**:
  1. Team prepares and preprocesses audio datasets.
  2. Train GAN/Autoencoder model with noise-reduction objectives.
  3. Store improved model.
  4. Deploy updated model into the device.
* **Relation**: **Included by UC3** (Noise Reduction uses the improved model).

---

## **UC6 – Evaluate Audio Quality (PESQ, STOI Metrics)**
* **Actor**: Development Team
* **Preconditions**: Model has been trained and test audio samples are available.
* **Postconditions**: Evaluation results are produced (PESQ, STOI scores).
* **Main Flow**:
  1. Team runs evaluation tests on noisy/cleaned audio pairs.
  2. Calculate PESQ and STOI metrics.
  3. Record and analyze scores.
  4. Provide feedback for further training.
* **Relation**: **Included by UC3** (Noise Reduction benefits from evaluation feedback).



