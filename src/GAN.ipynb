{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c5cf632",
   "metadata": {},
   "source": [
    "# Default GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6310ae",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3290613",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import librosa\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "import soundfile as sf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d208bd7",
   "metadata": {},
   "source": [
    "## init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ababfb05",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 1 = INFO, 2 = WARNING, 3 = ERROR\n",
    "from keras.models import load_model\n",
    "\n",
    "def calculate_psnr(original_signal, denoised_signal):  # Calculate PSNR\n",
    "    original_signal = original_signal.astype(float)\n",
    "    denoised_signal = denoised_signal.astype(float)\n",
    "    mse = np.mean((original_signal - denoised_signal) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    max_pixel = np.max(original_signal)\n",
    "    psnr = 20 * math.log10(max_pixel / math.sqrt(mse))\n",
    "    return psnr, mse\n",
    "\n",
    "# Load audio data\n",
    "def load_audio(file_path):\n",
    "    audio, sr = librosa.load(file_path, sr=16000)\n",
    "    return audio, sr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cf991a",
   "metadata": {},
   "source": [
    "## Generator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e627313",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    input_layer = Input(shape=(1,))\n",
    "    x = Dense(128, activation='relu')(input_layer)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    output_layer = Dense(1, activation='tanh')(x)\n",
    "    generator = Model(input_layer, output_layer)\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab852fdb",
   "metadata": {},
   "source": [
    "## Discriminator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9e5c21",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    input_layer = Input(shape=(1,))\n",
    "    x = Dense(64, activation='relu')(input_layer)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    output_layer = Dense(1, activation='sigmoid')(x)\n",
    "    discriminator = Model(input_layer, output_layer)\n",
    "    discriminator.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fa68f2",
   "metadata": {},
   "source": [
    "## Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5052d2fb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Build models\n",
    "generator = build_generator()\n",
    "discriminator = build_discriminator()\n",
    "\n",
    "# GAN model\n",
    "discriminator.trainable = False\n",
    "gan_input = Input(shape=(1,))\n",
    "generated_audio = generator(gan_input)\n",
    "gan_output = discriminator(generated_audio)\n",
    "gan = Model(gan_input, gan_output)\n",
    "gan.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e410db3",
   "metadata": {},
   "source": [
    "## Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb84e61",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Training parameters\n",
    "epochs = 1000\n",
    "batch_size = 128\n",
    "\n",
    "# Batch training with all files\n",
    "clean_files = [f for f in os.listdir('./clean') if f.endswith('.wav')]\n",
    "noisy_files = [f for f in os.listdir('./15dB') if f.endswith('.wav')]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for clean_file, noisy_file in zip(clean_files, noisy_files):\n",
    "        clean_audio, sr = load_audio(os.path.join('./clean', clean_file))\n",
    "        noisy_audio, sr = load_audio(os.path.join('./15dB', noisy_file))\n",
    "\n",
    "        # Ensure same length\n",
    "        min_length = min(len(clean_audio), len(noisy_audio))\n",
    "        clean_audio = clean_audio[:min_length]\n",
    "        noisy_audio = noisy_audio[:min_length]\n",
    "\n",
    "        # Normalize data\n",
    "        clean_audio = (clean_audio - np.mean(clean_audio)) / np.std(clean_audio)\n",
    "        noisy_audio = (noisy_audio - np.mean(noisy_audio)) / np.std(noisy_audio)\n",
    "\n",
    "        # Training data\n",
    "        X_train = noisy_audio.reshape(-1, 1)\n",
    "        y_train = clean_audio.reshape(-1, 1)\n",
    "\n",
    "        # Train discriminator\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        noisy_batch = X_train[idx]\n",
    "        clean_batch = y_train[idx]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
